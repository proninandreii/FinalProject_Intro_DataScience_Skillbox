#%%import dillimport pandas as pdimport transliteratefrom feature_engine.outliers import Winsorizerfrom sklearn.impute import SimpleImputerfrom sklearn.preprocessing import StandardScaler, OneHotEncoderfrom sklearn.compose import ColumnTransformerfrom sklearn.preprocessing import FunctionTransformerfrom sklearn.pipeline import Pipelinefrom sklearn.ensemble import GradientBoostingClassifierfrom sklearn.compose import make_column_selectorfrom sklearn.metrics import roc_auc_scorefrom sklearn.model_selection import train_test_splitfrom datetime import datetimefrom feature_engine.selection import DropFeaturesdef date_features(df):    df['visit_date'] = df['visit_date'].astype('datetime64[ns]')    df['Year'] = df['visit_date'].dt.year    df['Month'] = df['visit_date'].dt.month    df['Day'] = df['visit_date'].dt.day    return dfdef utm_features(df):    df['utm_source'].fillna(df['utm_source'].mode()[0], inplace=True)    social_media_sources = ('QxAxdyPLuQMEcrdZWdWb', 'MvfHsxITijuriZxsqZqt', 'ISrKoXQCxqqYvAZICvjs',                            'IZEXUFLARCUMynmHNBGo', 'PlbkrSYoHuZBWfYjYnfw', 'gVRrcxiDQubJiljoTbGm')    df['utm_source_is_social'] = df['utm_source'].isin(social_media_sources).astype(int)    df['utm_campaign'].fillna(df['utm_campaign'].mode()[0], inplace=True)    df['utm_adcontent'].fillna(df['utm_adcontent'].mode()[0], inplace=True)    df['utm_keyword'].fillna(df['utm_keyword'].mode()[0], inplace=True)    return dfdef device_brand(df):    df['device_brand'].fillna('other', inplace=True)    return dfdef time_features(df):    df['visit_time'] = df['visit_time'].astype('datetime64[ns]')    df['hour'] = df['visit_time'].dt.hour    df['minute'] = df['visit_time'].dt.minute    return dfdef screen_features(df):    df['screen_width'] = df['device_screen_resolution'].str.split('x').str[0].astype(int)    df['screen_height'] = df['device_screen_resolution'].str.split('x').str[1].astype(int)    return dfdef screen_features2(df):    df['device_screen_area'] = df['screen_width'] * df['screen_height']    df['device_screen_ratio'] = df['screen_width'] / df['screen_height']    return dfdef typisation(df):    df['Year'] = df['Year'].astype('int64')    df['Month'] = df['Month'].astype('int64')    df['Day'] = df['Day'].astype('int64')    df['hour'] = df['hour'].astype('int64')    df['minute'] = df['minute'].astype('int64')    return dfdef replace_numeric_with_most_common(df):    most_common_value = df['geo_city'].mode().iloc[0]    regex_filter = df['geo_city'].str.match(r'^-?\d+(\.\d+)?$')    df.loc[regex_filter, 'geo_city'] = most_common_value    return dfdef low_reg(df):    df = df.apply(lambda x: x.str.lower() if x.dtype == 'object' else x)    return dfdef translit(df):    def transliterate_text(text):        return transliterate.translit(text, 'ru', reversed=True)    df['geo_city'] = df['geo_city'].apply(lambda x: transliterate_text(x) if isinstance(x, str) else x)    return dfdef drop_duplicates(df):    df = df.drop_duplicates()    return dfdef load_data():    df_sessions = pd.read_csv('/Users/andreypronin/DataspellProjects/pythonProject/ga_sessions.csv', low_memory=False)    df_hits = pd.read_csv("/Users/andreypronin/DataspellProjects/pythonProject/ga_hits.csv", usecols=['session_id', 'event_action'], low_memory=False)    target_events = ['sub_car_claim_click', 'sub_car_claim_submit_click', 'sub_open_dialog_click',                    'sub_custom_question_submit_click', 'sub_call_number_click', 'sub_callback_submit_click',                    'sub_submit_success', 'sub_car_request_submit_click']    df_hits['target'] = df_hits['event_action'].isin(target_events)    is_target_event = df_hits.groupby('session_id')['target'].any().astype(int)    df = df_sessions.merge(is_target_event, on='session_id', how='inner')    df['target'] = df['target'].fillna(1)    return dfdef drop_col(df):    col_to_drop = ['session_id', 'client_id', 'visit_date',                   'visit_time', 'device_screen_resolution', 'device_model', 'device_os']    df = df.drop(col_to_drop)    return dfdef load_and_preprocess_data():    numerical = make_column_selector(dtype_include=['int64', 'float64', 'int32'])    categorical = make_column_selector(dtype_include=['category'])#обработка числовых    std_scaler = StandardScaler()    imputer = SimpleImputer(strategy='median')    pipe_num = Pipeline([        ('imputer', imputer),        ('scaler', std_scaler)])#обработка категориальных    ohe_encoder = OneHotEncoder(handle_unknown='ignore')    ohe_imputer = SimpleImputer(strategy='constant', fill_value='nan')    pipe_cat = Pipeline([        ('imputer', ohe_imputer),        ('encoder', ohe_encoder)])    preprocessor_features = ColumnTransformer(transformers=[        ('numerical', pipe_num, numerical),        ('category', pipe_cat, categorical)    ])    model = GradientBoostingClassifier(n_estimators=200, max_depth=5, learning_rate=0.1)    #Модель была выбрана из файла Pipeline_test_modelling, но до этого был проведен и GridSearchCV. Для наглядности    #все равно повторю train_test_split для указания roc auc метрики и затем обучу на всех данных    pipe = Pipeline(steps=[        ('screen_features', FunctionTransformer(screen_features)),        ('delete_outliers', Winsorizer()),        #Удаление выбросов привычным образом не работает, так как sklearn.pipeline не обрабатывает датафрейм, а только X не трогая y.        #Что не было упомянуто в курсе, поэтому множество функций изменяющих количество строк не работают через FunctionTransformer,        #Так как изменяется X, но не Y. Самостоятельно получилось найти такое решение для удаления выбросов.        ('date_features', FunctionTransformer(date_features)),        ('utm_source', FunctionTransformer(utm_features)),        ('device_brand', FunctionTransformer(device_brand)),        ('time_features', FunctionTransformer(time_features)),        ('screen_2', FunctionTransformer(screen_features2)),        ('replace_numeric', FunctionTransformer(replace_numeric_with_most_common)),        ('typisation', FunctionTransformer(typisation)),        ('low_reg', FunctionTransformer(low_reg)),        ('drop_duplicates', FunctionTransformer(drop_duplicates)),        ('dropper', DropFeatures(['session_id', 'client_id', 'visit_date',                                      'visit_time', 'device_screen_resolution', 'device_model', 'device_os'])),        ('preprocessor_features', preprocessor_features),        ('classifier', model)    ])    df = load_data()    X = df.drop('target', axis=1)    y = df['target']    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)    pipe.fit(X_train, y_train)    y_proba = pipe.predict_proba(X_test)[:, 1]    roc_auc = roc_auc_score(y_test, y_proba)    print(f'roc_auc: {roc_auc:.4f}')    pipe.fit(X, y)    with open('final_model.pkl', 'wb') as file:        dill.dump({            'model': pipe,            'metadata': {                'name': 'Target prediction Sber',                'author': 'Andrey Pronin',                'version': 1,                'date': datetime.now(),                'type': type(pipe.named_steps['classifier']).__name__,                'metric': roc_auc            }        }, file)if __name__ == '__main__':    load_and_preprocess_data()